{"cells":[{"cell_type":"markdown","metadata":{},"source":["This is a model from https://www.kaggle.com/code/nakulsingh1289/face-expression-detection-from-scratch/notebook\n","\n","modified to meet a more modern keras style and improved coding style"]},{"cell_type":"markdown","metadata":{},"source":["## Image augmentation using keras ImageDataGenerator"]},{"cell_type":"code","execution_count":1,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-10-17 14:16:00.367991: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-10-17 14:16:00.465320: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2022-10-17 14:16:00.845795: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-11.1/targets/x86_64-linux/lib:/usr/local/cuda-11.7/targets/x86_64-linux/lib\n","2022-10-17 14:16:00.845839: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-11.1/targets/x86_64-linux/lib:/usr/local/cuda-11.7/targets/x86_64-linux/lib\n","2022-10-17 14:16:00.845843: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]},{"name":"stdout","output_type":"stream","text":["Found 23060 images belonging to 7 classes.\n","Found 5761 images belonging to 7 classes.\n","Found 7066 images belonging to 7 classes.\n"]}],"source":["# building data generator\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","base_path = \"./images/\"\n","batch_size = 64\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1.0 / 255.0,\n","    validation_split=0.2,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    rotation_range=20,\n","    horizontal_flip=True,\n","    vertical_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","valid_datagen = ImageDataGenerator(\n","    rescale=1.0 / 255.0,\n","    validation_split=0.2\n",")\n","test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    base_path + \"train\",\n","    target_size=(48, 48),\n","    subset=\"training\",\n","    batch_size=batch_size,\n","    class_mode='categorical',\n",")\n","\n","validation_generator = valid_datagen.flow_from_directory(\n","    base_path + 'train',\n","    target_size=(48, 48),\n","    class_mode='categorical',\n","    subset='validation',\n","    batch_size=batch_size\n",")\n","\n","test_data_generator = test_datagen.flow_from_directory(\n","    base_path + \"validation\",\n","    target_size=(48, 48),\n","    batch_size=batch_size,\n","    class_mode='categorical',\n",")\n"]},{"cell_type":"markdown","metadata":{},"source":["# Defining our 4 Convolution and 2 Dense layers model"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-10-17 14:16:01.897285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-10-17 14:16:01.921913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-10-17 14:16:01.922061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-10-17 14:16:01.922419: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-10-17 14:16:01.922665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-10-17 14:16:01.922793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-10-17 14:16:01.922906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-10-17 14:16:02.246811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-10-17 14:16:02.246954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-10-17 14:16:02.247061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-10-17 14:16:02.247160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5743 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:07:00.0, compute capability: 7.5\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," efficientnetb0 (Functional)  (None, 2, 2, 1280)       4049571   \n","                                                                 \n"," dropout (Dropout)           (None, 2, 2, 1280)        0         \n","                                                                 \n"," flatten (Flatten)           (None, 5120)              0         \n","                                                                 \n"," batch_normalization (BatchN  (None, 5120)             20480     \n"," ormalization)                                                   \n","                                                                 \n"," dense (Dense)               (None, 32)                163872    \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 32)               128       \n"," hNormalization)                                                 \n","                                                                 \n"," activation (Activation)     (None, 32)                0         \n","                                                                 \n"," dropout_1 (Dropout)         (None, 32)                0         \n","                                                                 \n"," dense_1 (Dense)             (None, 32)                1056      \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 32)               128       \n"," hNormalization)                                                 \n","                                                                 \n"," activation_1 (Activation)   (None, 32)                0         \n","                                                                 \n"," dropout_2 (Dropout)         (None, 32)                0         \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                1056      \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 32)               128       \n"," hNormalization)                                                 \n","                                                                 \n"," activation_2 (Activation)   (None, 32)                0         \n","                                                                 \n"," dense_3 (Dense)             (None, 7)                 231       \n","                                                                 \n","=================================================================\n","Total params: 4,236,650\n","Trainable params: 4,184,195\n","Non-trainable params: 52,455\n","_________________________________________________________________\n"]},{"name":"stderr","output_type":"stream","text":["/home/huukhang1512/.local/share/virtualenvs/CSCI218Project-Temd_YmO/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]}],"source":["from keras.optimizers import SGD\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\n","from keras.models import Model\n","from keras.models import Sequential\n","from keras.applications import EfficientNetB0\n","from keras.optimizers import Adam\n","from keras import optimizers, layers\n","\n","# number of possible label values\n","nb_classes = 7\n","IMAGE_SIZE = 48\n","\n","base_model = EfficientNetB0(input_shape=(\n","    48, 48, 3), include_top=False, weights=\"imagenet\")\n","# for layer in base_model.layers[:-4]:\n","#     layer.trainable=False\n","\n","model = Sequential([\n","    base_model,\n","    Dropout(0.5),\n","    Flatten(),\n","    BatchNormalization(),\n","    Dense(32, kernel_initializer='he_uniform'),\n","    BatchNormalization(),\n","    Activation('relu'),\n","    Dropout(0.5),\n","    Dense(32, kernel_initializer='he_uniform'),\n","    BatchNormalization(),\n","    Activation('relu'),\n","    Dropout(0.5),\n","    Dense(32, kernel_initializer='he_uniform'),\n","    BatchNormalization(),\n","    Activation('relu'),\n","    Dense(7, activation='softmax'),\n","])\n","model.summary()\n","\n","# opt = SGD(lr=0.01)\n","# model.compile(loss=\"categorical_crossentropy\",\n","#               optimizer=opt, metrics=['accuracy'])\n","\n","model.compile(Adam(lr=0.01), loss='categorical_crossentropy')\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","es = EarlyStopping(verbose=1,patience=20)  \n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n","                              patience=20, min_lr=1e-10)"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n"]},{"name":"stderr","output_type":"stream","text":["2022-10-17 14:16:08.700769: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8204\n"]},{"name":"stdout","output_type":"stream","text":["361/361 [==============================] - 30s 66ms/step - loss: 1.8303 - val_loss: 1.8096 - lr: 0.0100\n","Epoch 2/50\n","361/361 [==============================] - 22s 62ms/step - loss: 1.7974 - val_loss: 4.3822 - lr: 0.0100\n","Epoch 3/50\n","361/361 [==============================] - 22s 62ms/step - loss: 1.7833 - val_loss: 1.8332 - lr: 0.0100\n","Epoch 4/50\n","361/361 [==============================] - 22s 62ms/step - loss: 1.7587 - val_loss: 29.8418 - lr: 0.0100\n","Epoch 5/50\n","361/361 [==============================] - 22s 62ms/step - loss: 1.7161 - val_loss: 6.4589 - lr: 0.0100\n","Epoch 6/50\n","361/361 [==============================] - 22s 62ms/step - loss: 1.6613 - val_loss: 1.9331 - lr: 0.0100\n","Epoch 7/50\n","361/361 [==============================] - 23s 62ms/step - loss: 1.6037 - val_loss: 3.2534 - lr: 0.0100\n","Epoch 8/50\n","361/361 [==============================] - 22s 62ms/step - loss: 1.5645 - val_loss: 1.8821 - lr: 0.0100\n","Epoch 9/50\n","361/361 [==============================] - 23s 63ms/step - loss: 1.5294 - val_loss: 2.1062 - lr: 0.0100\n","Epoch 10/50\n","361/361 [==============================] - 23s 62ms/step - loss: 1.5142 - val_loss: 2.1673 - lr: 0.0100\n","Epoch 11/50\n","361/361 [==============================] - 22s 62ms/step - loss: 1.4899 - val_loss: 2.0955 - lr: 0.0100\n","Epoch 12/50\n","361/361 [==============================] - 22s 62ms/step - loss: 1.4745 - val_loss: 1.8716 - lr: 0.0100\n","Epoch 13/50\n","361/361 [==============================] - 23s 62ms/step - loss: 1.4750 - val_loss: 1.9126 - lr: 0.0100\n","Epoch 14/50\n","361/361 [==============================] - 22s 62ms/step - loss: 1.4676 - val_loss: 1.6938 - lr: 0.0100\n","Epoch 15/50\n","361/361 [==============================] - 22s 62ms/step - loss: 1.4542 - val_loss: 2.0878 - lr: 0.0100\n","Epoch 16/50\n","361/361 [==============================] - 22s 61ms/step - loss: 1.4445 - val_loss: 2.0707 - lr: 0.0100\n","Epoch 17/50\n","361/361 [==============================] - 22s 60ms/step - loss: 1.4394 - val_loss: 2.0152 - lr: 0.0100\n","Epoch 18/50\n","361/361 [==============================] - 22s 60ms/step - loss: 1.4338 - val_loss: 4.2711 - lr: 0.0100\n","Epoch 19/50\n","361/361 [==============================] - 22s 60ms/step - loss: 1.4262 - val_loss: 1.9836 - lr: 0.0100\n","Epoch 20/50\n","361/361 [==============================] - 23s 64ms/step - loss: 1.4211 - val_loss: 1.9138 - lr: 0.0100\n","Epoch 21/50\n","361/361 [==============================] - 23s 63ms/step - loss: 1.4237 - val_loss: 2.1544 - lr: 0.0100\n","Epoch 22/50\n","361/361 [==============================] - 22s 62ms/step - loss: 1.4294 - val_loss: 2.0000 - lr: 0.0100\n","Epoch 23/50\n","361/361 [==============================] - 22s 62ms/step - loss: 1.4173 - val_loss: 1.9179 - lr: 0.0100\n","Epoch 24/50\n","361/361 [==============================] - 22s 61ms/step - loss: 1.4077 - val_loss: 1.9526 - lr: 0.0100\n","Epoch 25/50\n","361/361 [==============================] - 22s 61ms/step - loss: 1.4002 - val_loss: 1.9164 - lr: 0.0100\n","Epoch 26/50\n","361/361 [==============================] - 22s 61ms/step - loss: 1.3978 - val_loss: 1.9380 - lr: 0.0100\n","Epoch 27/50\n","361/361 [==============================] - 22s 61ms/step - loss: 1.3937 - val_loss: 2.0186 - lr: 0.0100\n","Epoch 28/50\n","361/361 [==============================] - 22s 61ms/step - loss: 1.3999 - val_loss: 1.9576 - lr: 0.0100\n","Epoch 29/50\n","361/361 [==============================] - 22s 62ms/step - loss: 1.3933 - val_loss: 2.6105 - lr: 0.0100\n","Epoch 30/50\n","361/361 [==============================] - 23s 63ms/step - loss: 1.3894 - val_loss: 2.0387 - lr: 0.0100\n","Epoch 31/50\n","361/361 [==============================] - 22s 62ms/step - loss: 1.3792 - val_loss: 4.3864 - lr: 0.0100\n","Epoch 32/50\n","361/361 [==============================] - 21s 59ms/step - loss: 1.3835 - val_loss: 30.3534 - lr: 0.0100\n","Epoch 33/50\n","361/361 [==============================] - 22s 60ms/step - loss: 1.3769 - val_loss: 20.4206 - lr: 0.0100\n","Epoch 34/50\n","361/361 [==============================] - 22s 60ms/step - loss: 1.3664 - val_loss: 1.8855 - lr: 0.0100\n","Epoch 34: early stopping\n"]}],"source":["# number of epochs to train the NN\n","from keras.callbacks import ModelCheckpoint\n","epochs = 50\n","\n","# checkpoint to save best model\n","\n","# checkpoint = ModelCheckpoint(\"model.h5\")\n","history = model.fit(\n","    train_generator,\n","    epochs=epochs,\n","    validation_data=validation_generator,\n","    callbacks=[reduce_lr,es],\n","    verbose=1\n",")"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[],"source":["from matplotlib import pyplot as plt\n","\n","# visualise training and testing accuracy and loss\n","def plot_results(history):\n","    acc = history.history['accuracy']\n","    val_acc = history.history['val_accuracy']\n","    loss = history.history['loss']\n","    val_loss = history.history['val_loss']\n","\n","    epochs = range(1, len(acc) + 1)\n","\n","    plt.figure(figsize = (24, 6))\n","    plt.subplot(1, 2, 1)\n","    plt.plot(epochs, acc, 'b', label='Training Accuracy')\n","    plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n","    plt.grid(True)\n","    plt.legend()\n","    plt.xlabel('Epoch')\n","\n","    plt.subplot(1, 2, 2)\n","    plt.plot(epochs, loss, 'b', label='Training Loss')\n","    plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","    plt.grid(True)\n","    plt.legend()\n","    plt.xlabel('Epoch')\n","    plt.show()\n"," \n","# print best epoch with best accuracy on validation\n","def get_best_epoch(history):\n","    valid_acc = history.history['val_accuracy']\n","    best_epoch = valid_acc.index(max(valid_acc)) + 1\n","    best_acc = max(valid_acc)\n","    print('Best Validation Accuracy Score {:0.5f}, is for epoch {}'.format( best_acc, best_epoch))"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[{"ename":"KeyError","evalue":"'accuracy'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m get_best_epoch(history)\n","Cell \u001b[0;32mIn [5], line 5\u001b[0m, in \u001b[0;36mplot_results\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_results\u001b[39m(history):\n\u001b[0;32m----> 5\u001b[0m     acc \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m     val_acc \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","\u001b[0;31mKeyError\u001b[0m: 'accuracy'"]}],"source":["plot_results(history)\n","get_best_epoch(history)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"interpreter":{"hash":"d0200e073fca29e67cf5880a507d321700bbcf10a13f0f4ea8bd144ddf280b83"},"kernelspec":{"display_name":"Python 3.10.6 64-bit ('CSCI218Project-Temd_YmO': pipenv)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"67759c7270b54abb58d1efb12f2ccfbec46054dee60f7fe60b4bb0322336d082"}}},"nbformat":4,"nbformat_minor":4}
